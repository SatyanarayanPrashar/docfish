import os
import openai
from dotenv import load_dotenv

# Import the main function from split_data.py which handles loading and splitting
# Assumes split_data.py is in a 'splitter' subdirectory.
# If split_data.py is in the same directory, use: from split_data import splitter_main
try:
    from splitter.split_data import splitter_main
except ImportError:
    print("Error: Could not import 'splitter_main' from 'splitter.split_data'.")
    print("Ensure 'split_data.py' exists in a 'splitter' subdirectory relative to 'main.py',")
    print("or adjust the import statement in 'main.py' if it's located elsewhere.")
    exit()

# Import necessary Langchain components (similar to create_database.py)
from langchain_openai import OpenAIEmbeddings
from langchain_qdrant import QdrantVectorStore
from langchain.schema import Document # Often useful for type hints

# Load environment variables (especially OPENAI_API_KEY)
load_dotenv()
openai_api_key = os.environ.get('OPENAI_API_KEY')
if not openai_api_key:
    print("Error: OPENAI_API_KEY not found in environment variables.")
    print("Please ensure it is set in your .env file or system environment.")
    exit()
openai.api_key = openai_api_key # Set it for the openai library if needed elsewhere

# --- Configuration ---
# Qdrant Configuration (can be overridden by environment variables)
QDRANT_URL = os.environ.get("QDRANT_URL", "http://localhost:6333")
QDRANT_COLLECTION_NAME = os.environ.get("QDRANT_COLLECTION_NAME", "code_repo_embeddings") # Choose a descriptive name

# Embedding Model Configuration
EMBEDDING_MODEL = "text-embedding-3-large"
# --- End Configuration ---


def create_and_save_embeddings(chunks: list[Document]):
    """
    Initializes the embedder, creates embeddings for the chunks,
    and saves them to the specified Qdrant vector store.

    Args:
        chunks: A list of Langchain Document objects (the split text chunks).
    """
    print(f"\n--- Step 2: Initializing Embedder and Saving to Qdrant ---")
    print(f"Using embedding model: {EMBEDDING_MODEL}")
    try:
        embedder = OpenAIEmbeddings(
            model=EMBEDDING_MODEL,
            api_key=openai_api_key
            # dimensions=1024 # Optional: Specify dimensions if required by model/Qdrant setup
        )
    except Exception as e:
        print(f"❌ Error initializing OpenAI Embeddings: {e}")
        return

    print(f"Connecting to Qdrant at: {QDRANT_URL}")
    print(f"Using collection: {QDRANT_COLLECTION_NAME}")
    print(f"Attempting to add {len(chunks)} chunks to the vector store...")

    try:
        # Use QdrantVectorStore.from_documents to create/update the collection
        vector_store = QdrantVectorStore.from_documents(
            documents=chunks,
            embedding=embedder,
            url=QDRANT_URL,
            collection_name=QDRANT_COLLECTION_NAME,
            prefer_grpc=False, # Set to True if using gRPC
            # force_recreate=True, # Uncomment to wipe the collection and start fresh on each run
        )
        print(f"✅ Successfully added/updated {len(chunks)} documents in Qdrant collection '{QDRANT_COLLECTION_NAME}'.")
        # return vector_store # Optionally return the vector store object if needed later

    except Exception as e:
        print(f"❌ Error connecting to or writing to Qdrant: {e}")
        print("Please ensure:")
        print(f"  - Qdrant server is running and accessible at {QDRANT_URL}.")
        print(f"  - The collection name '{QDRANT_COLLECTION_NAME}' is valid.")
        print(f"  - Your OpenAI API key is valid and has sufficient quota.")
        print(f"  - Network connectivity is stable.")


if __name__ == "__main__":
    print("Starting the process: Load Repo -> Split -> Embed -> Save to Qdrant")

    # 1. Load and Split Data using splitter_main from split_data.py
    # This function internally defines the repo path and performs loading/splitting.
    print("\n--- Step 1: Loading and Splitting Documents from Repository ---")
    document_chunks = None
    try:
        # splitter_main handles collecting documents from the repo path
        # defined within it (e.g., './quiz-edloops') and splitting them.
        document_chunks = splitter_main() # Returns the list of Document chunks

        if not document_chunks:
             print("⚠️ No document chunks were generated by splitter_main. Check repository path and file filters in split_data.py.")
             exit()
        # splitter_main already prints status messages during its execution
        print(f"Successfully generated {len(document_chunks)} chunks.")

    except FileNotFoundError:
         print(f"❌ Error: Could not find the repository path specified within splitter_main in split_data.py.")
         print("   Please ensure the repository exists at the relative path defined inside split_data.py (likely './quiz-edloops').")
         exit()
    except Exception as e:
         print(f"❌ An unexpected error occurred during loading/splitting: {e}")
         exit()

    # 2. Create Embeddings and Save to Qdrant
    if document_chunks:
        create_and_save_embeddings(document_chunks)
    else:
        print("Skipping embedding and saving step as no chunks were generated.")

    print("\nProcess finished.")